{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geological Interpretor Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for testing and developping some of the basic code in this package."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ontology manipulation\n",
    "\n",
    "The knowledge manipulated in this package is formalised in an ontology,<br>\n",
    "which is store in a *.owl* file.\n",
    "\n",
    "It is named **MOGI** for **M**inimal **O**ntology for **G**eological **I**nterpretation\n",
    "\n",
    "To manipulated this ontology, we use the package **owlready2** available from here: https://owlready2.readthedocs.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import owlready2 as owl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl.onto_path.append(\"../ontologies/\")\n",
    "mogi = owl.get_ontology(\"mogi.owl\").load()\n",
    "mogi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ontology provides access to its components, e.g.:\n",
    "* classes\n",
    "* properties\n",
    "* individuals\n",
    "* rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(mogi.classes()))\n",
    "print(list(mogi.properties()))\n",
    "print(list(mogi.individuals()))\n",
    "print(list(mogi.rules()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specific elements can be searched through simple queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mogi.search(iri = \"*Surface\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoner\n",
    "\n",
    "Ontologies are even more powerful thansk to their capabilities to use reasoning for infering types, properties, and relationships that were not explicitly stated.\n",
    "This is usefull for obtaining results implied by the already stated information.\n",
    "\n",
    "This is achieved by running a *reasoner* on the ontology as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl.sync_reasoner(infer_property_values=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataset\n",
    "\n",
    "Data are actually described within the ontology, here thanks to the *Data* class.<br>\n",
    "Adding new data points calls for creating new *Data* individuals (i.e., instances in the ontology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_head = np.array(['name', 'x', 'y', 'z', 'dip_dir', 'dip', 'geology'])\n",
    "data_array = np.array([['D1', 15, 20, 35, 270, 45, 'Trias_Base'],\n",
    "                       ['D2', 30, 25, 50, 270, 45, 'Trias_Base'],\n",
    "                       ['D3', 60, 30, 40, 90, 45, 'Trias_Base'],\n",
    "                       ['D4', 75, 15, 25, 90, 45, 'Trias_Base'],\n",
    "                       ['D5', 110, 20, 40, 270, 63, 'Trias_Base'],\n",
    "                       ['D6', 120, 20, 60, 270, 64, 'Trias_Base'],\n",
    "                       ['D7', 155, 20, 60, 89, 39, 'Trias_Base'],\n",
    "                       ['D8', 190, 20, 30, 91, 40, 'Trias_Base'],\n",
    "                       ['D11', 25, 22, 45, np.nan, np.nan, np.nan],\n",
    "                       ['D22', 50, 22, 50, np.nan, np.nan, np.nan],\n",
    "                       ['D44', 100, 30, 20, np.nan, np.nan, np.nan],\n",
    "                       ['D77', 168, 30, 47, np.nan, np.nan, np.nan]]\n",
    ")\n",
    "dataset = pd.DataFrame(data = data_array, columns = data_head)\n",
    "dataset.set_index(\"name\", inplace = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing any data already stored in the project\n",
    "for data_i in mogi.search(type = mogi.Ponctual_Observation):\n",
    "    owl.destroy_entity(data_i)\n",
    "mogi.search(type = mogi.Ponctual_Observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the dataset in the ontology by creating individuals\n",
    "for name_i, values_i in dataset.iterrows():\n",
    "    mogi.Ponctual_Observation(name_i, **{key:[val] for key, val in values_i.items()})\n",
    "mogi.search(type = mogi.Ponctual_Observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading dataset from the ontology\n",
    "dataset = pd.DataFrame(columns=[\"name\",\"x\",\"y\",\"z\",\"dip_dir\",\"dip\",'geology'])\n",
    "dataset.set_index(\"name\")\n",
    "for di in mogi.search(type = mogi.Ponctual_Observation):\n",
    "    for prop in di.get_properties():\n",
    "        for value in prop[di]:\n",
    "            dataset.loc[di.name,prop.name] = value\n",
    "dataset.drop(columns=\"name\", inplace=True)\n",
    "dataset.reset_index(inplace=True,names=\"name\")\n",
    "dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(center, dip, dir, length= 1, ax= None, color = \"black\", **kargs):\n",
    "    ax_plt = plt if ax is None else ax\n",
    "\n",
    "    center = np.array(center)\n",
    "    dip_rad = np.deg2rad(dip)\n",
    "    vec_x =  np.cos(dip_rad)\n",
    "    if dir == \"left\": vec_x *= -1\n",
    "    vec_z = -np.sin(dip_rad)\n",
    "    vect = 0.5 * length * np.array([vec_x,vec_z])\n",
    "    start = center - vect\n",
    "    end = center + vect\n",
    "    ax_plt.plot([start[0],end[0]],[start[1],end[1]], color = color, **kargs)\n",
    "    \n",
    "    return vect\n",
    "    \n",
    "def draw_dip_symbol(center, dip, dir, length= 1, polarity= None, ax= None, color = \"black\", **kargs):\n",
    "    ax_plt = plt if ax is None else ax\n",
    "    \n",
    "    vect = draw_line(center= center, dip= dip, dir= dir, length= length, ax= ax_plt, color = color, **kargs)\n",
    "    \n",
    "    if polarity is not None:\n",
    "        vect_pol = 0.2 * np.array([-vect[1],vect[0]])\n",
    "        if (dir == \"left\" and polarity == \"up\") or (dir == \"right\" and polarity == \"down\") : vect_pol *= -1\n",
    "        ax_plt.arrow(*center,*vect_pol, width=length/100, color = color, **kargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_line([0,0],30, \"left\")\n",
    "draw_dip_symbol([0,1],60, \"right\", polarity= \"up\", color= \"red\" )\n",
    "plt.gca().set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
