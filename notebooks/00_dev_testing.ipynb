{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geological Interpretor Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for testing and developping some of the basic code in this package."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ontology manipulation\n",
    "\n",
    "The knowledge manipulated in this package is formalised in an ontology,<br>\n",
    "which is store in a *.owl* file.\n",
    "\n",
    "It is named **MOGI** for **M**inimal **O**ntology for **G**eological **I**nterpretation\n",
    "\n",
    "To manipulated this ontology, we use the package **owlready2** available from here: https://owlready2.readthedocs.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import owlready2 as owl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl.onto_path.append(\"../ontologies/\")\n",
    "mogi = owl.get_ontology(\"mogi.owl\").load()\n",
    "mogi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ontology provides access to its components, e.g.:\n",
    "* classes\n",
    "* properties\n",
    "* individuals\n",
    "* rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(mogi.classes()))\n",
    "print(list(mogi.properties()))\n",
    "print(list(mogi.individuals()))\n",
    "print(list(mogi.rules()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specific elements can be searched through simple queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mogi.search(iri = \"*Surface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = mogi.Geologic_Context('Data_properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.INDIRECT_get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl.Thing.get_properties(owl.Thing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoner\n",
    "\n",
    "Ontologies are even more powerful thansk to their capabilities to use reasoning for infering types, properties, and relationships that were not explicitly stated.\n",
    "This is usefull for obtaining results implied by the already stated information.\n",
    "\n",
    "This is achieved by running a *reasoner* on the ontology as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl.sync_reasoner(infer_property_values=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geological Knowledge Manager"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GeologicalKnowledgeManager** may know different instances of **GeologicalKnowledgeFramework**,<br>\n",
    "for example to allow differenciating scenarios or for allowing customisation of knowledge and its formalisation.\n",
    "\n",
    "**GeologicalKnowledgeFramework** provides access to concept definitions for providing knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class GeologicalKnowledgeManager(object):\n",
    "    \"\"\"GeologicalKnowledgeManager is managing one or several GeologicalKnowledgeFramework.\n",
    "    \n",
    "    The GeologicalKnowledgeManager is typically a singleton, so there is always one and only one instance of it.\n",
    "    \n",
    "    The GeologicalKnowledgeManager may know different instances of GeologicalKnowledgeFramework,\n",
    "    for example to allow different interpretation scenarios or for allowing user-specific customisation\n",
    "    of knowledge and its formalisation.\n",
    "    \n",
    "    GeologicalKnowledgeFramework are typically ontologies and extensions defined in this package or elsewhere.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __new__(cls):\n",
    "        \"\"\"Method to access (and create if needed) the only allowed instance of this class.\n",
    "        \n",
    "        Returns:\n",
    "        - an instance of GeologicalKnowledgeManager\"\"\"\n",
    "        if not hasattr(cls, 'instance'):\n",
    "            cls.instance = super(GeologicalKnowledgeManager, cls).__new__(cls)\n",
    "            cls.initialised= False\n",
    "            print(\"DEBUG::creates new manager\")\n",
    "        return cls.instance\n",
    "        \n",
    "    def __init__(self, default= \"mogi\", default_source_directory= \"../ontologies/\", default_source_file= \"mogi.owl\", default_ontology_backend= \"owlready2\"):\n",
    "        \"\"\"Initializes the GeologicalKnowledgeManager with some default values from configuration.\n",
    "        \n",
    "        Parameters:\n",
    "        - default: specifies the name of the default knowledge framework\n",
    "        - default_source_directory: specifies the default folder containing of the knowledge framework definitions\n",
    "        - default_source_file: file contained in the source_directory defining the knowledge framework (e.g., .owl file)\n",
    "        - default_ontology_backend: specifies the default ontology backend to be used\n",
    "        \"\"\"\n",
    "        print(\"DEBUG::__init__\")\n",
    "        if not self.initialised:\n",
    "            self._initialise(default= default, default_source_directory= default_source_directory, default_source_file= default_source_file, default_ontology_backend= default_ontology_backend)\n",
    "            \n",
    "    def _initialise(self, default, default_source_directory, default_source_file, default_ontology_backend):\n",
    "        \"\"\"Initializes the GeologicalKnowledgeManager with some default values from configuration.\n",
    "        \n",
    "        Parameters:\n",
    "        - default: specifies the name of the default knowledge framework\n",
    "        - default_source_directory: specifies the default folder containing of the knowledge framework definitions\n",
    "        - default_source_file: file contained in the source_directory defining the knowledge framework (e.g., .owl file)\n",
    "        - default_ontology_backend: specifies the default ontology backend to be used\n",
    "        \"\"\"\n",
    "        print(\"DEBUG::initialize manager\")\n",
    "        self.default= default\n",
    "        self.default_source_directory= default_source_directory\n",
    "        self.default_source_file= default_source_file\n",
    "        self.default_ontology_backend= default_ontology_backend\n",
    "        \n",
    "        self.knowledge_framework_dict = {}\n",
    "        \n",
    "        self.initialised= True\n",
    "        \n",
    "    def reset(self, default= \"mogi\", default_source_directory= \"../ontologies/\", default_source_file= \"mogi.owl\", default_ontology_backend= \"owlready2\"):\n",
    "        \"\"\"Reinitializes the GeologicalKnowledgeManager with some default values from configuration.\n",
    "        \n",
    "        Parameters:\n",
    "        - default: specifies the name of the default knowledge framework\n",
    "        - default_source_directory: specifies the default folder containing of the knowledge framework definitions\n",
    "        - default_source_file: file contained in the source_directory defining the knowledge framework (e.g., .owl file)\n",
    "        - default_ontology_backend: specifies the default ontology backend to be used\n",
    "        \"\"\"\n",
    "        print(\"DEBUG::reset manager\")\n",
    "        self._initialise(default= default, default_source_directory= default_source_directory, default_source_file= default_source_file, default_ontology_backend= default_ontology_backend)\n",
    "             \n",
    "    def load_knowledge_framework(self, name=None, source= None, source_directory= None, backend= None):\n",
    "        \"\"\"Gets and initilises the ontology from the specified source.\n",
    "        \n",
    "        Parameters:\n",
    "        - name: the name to be given to the knowledge framework. If None (default) the file name will be used.\n",
    "        - source: filename to the ontology source. If None(default) the default ontology is used.\n",
    "        - source_directory: where the system should look for ontology definition files. If None, the `GeologicalKnowledgeFramework` will decide.\n",
    "        - backend: the ontology backend to be used. If None, the `GeologicalKnowledgeFramework` will decide.\"\"\"\n",
    "        source = source if source is not None else self.default_source_file\n",
    "        name = name if name is not None else os.path.basename(source).split(os.path.extsep)[0]\n",
    "        self.knowledge_framework_dict[name] = GeologicalKnowledgeFramework(name= name, source= source, source_directory= source_directory, backend= backend)\n",
    "    \n",
    "    def get_knowledge_framework(self,name= \"default\"):\n",
    "        \"\"\"Accessor to knowledge frameworks.\"\"\"\n",
    "        name = self.default if name == \"default\" else name\n",
    "        assert len(self.knowledge_framework_dict) > 0, \"No ontology has been loaded yet. Please use GeologicalKnowledgeManager().load_knowledge_framework() first\"\n",
    "        assert name in self.knowledge_framework_dict.keys(), \"The specified ontology hasn't been loaded: \"+name+\\\n",
    "            \"\\navailable ontology names are: \"+\"\\n\".join(self.knowledge_framework_dict.keys())\n",
    "        return self.knowledge_framework_dict[name]\n",
    "    \n",
    "class GeologicalKnowledgeFramework(object):\n",
    "    \"\"\"A GeologicalKnowledgeFramework holds the definition of concepts and relationships describing knowledge.\n",
    "    \n",
    "    This is typically an overlay around a formal ontology definition, which also brings additional capabilities,\n",
    "    such as algorithms and factories to achieve specific tasks and create objects.\"\"\"\n",
    "    \n",
    "    def __init__(self, name, source, source_directory= None, backend= None):\n",
    "        \"\"\"Initialise a KnowledgeFramework form a given ontology file (source).\n",
    "        \n",
    "        Parameters:\n",
    "        - name: should be the name under which this KnowledgeFramework is known in the manager\n",
    "        - source: the source file for the ontology definition\n",
    "        - source_directory: the directory where the source files for the ontology definition are looked for.\n",
    "        If None (default) the default path provided by the `KnowledgeManager` is used.\n",
    "        - backend: the ontology backend to be used for this knwoledge framework.\n",
    "        If None (default) the default ontology backend provided by the `KnowledgeManager` is used.\"\"\"\n",
    "        self.name= name\n",
    "        print(source)\n",
    "        self.__source_directory= None\n",
    "        self.init_source_directory(source_directory)\n",
    "        self.initialise_ontology_backend(backend)\n",
    "        print(source)\n",
    "        self.load_ontology(source)\n",
    "    \n",
    "    def init_source_directory(self, source_directory):\n",
    "        \"\"\"Initialises the folder where source files are searched.\n",
    "        \n",
    "        Parameters:\n",
    "        - source_directory: if None, the previous value is used if it wasn't None, else the `GeologicalKnowledgeManager`default is used.\"\"\"\n",
    "        if source_directory is not None:\n",
    "            self.__source_directory= source_directory\n",
    "        elif self.__source_directory is None:\n",
    "            self.__source_directory= GeologicalKnowledgeManager().default_source_directory\n",
    "    \n",
    "    def initialise_ontology_backend(self, backend_name:str= None):\n",
    "        \"\"\"Initializes the ontology package used as a backend to access ontologies.\n",
    "        \n",
    "        This will:\n",
    "        - try to import the backend as onto\n",
    "        - set the default path for ontologies\"\"\"\n",
    "                \n",
    "        self.__ontology_backend = None\n",
    "        backend_name= GeologicalKnowledgeManager().default_ontology_backend if backend_name is None else backend_name\n",
    "        if backend_name == \"owlready2\":\n",
    "            try:\n",
    "                import owlready2 as owl2 \n",
    "                self.__ontology_backend = owl2\n",
    "                if self.__source_directory not in self.__ontology_backend.onto_path:\n",
    "                    self.__ontology_backend.onto_path.append(self.__source_directory)\n",
    "            except ImportError:\n",
    "                raise ImportError(\"Your are trying to use Owlready2 as a backend for ontology management, but it doesn't appear to be installed.\"\\\n",
    "                \"This is either because OwlReady2 is given as default option or because you asked for it.\"\\\n",
    "                \"Please install the OwlReady2 package from https://owlready2.readthedocs.io\"\\\n",
    "                \"or give another backend through GeologicalKnowledgeManager().initialise_ontology_backend()\")\n",
    "                \n",
    "            # also test if java is correctly installed & accessible, as it is used by owlready2 for reasoning\n",
    "            try:\n",
    "                os.system(\"java -version\")\n",
    "            except:\n",
    "                raise ImportError(\"Java doesn't appear to be installed properly as the command `java -version` returned an error.\"\\\n",
    "                    \"This error occured while loading owlready2 package as an ontology backend, because java is used for the reasoning engine.\")\n",
    "        else:\n",
    "            raise Exception(\"The specified backed for ontology is not supported: \"+backend_name)\n",
    "          \n",
    "        \n",
    "    def load_ontology(self, source):\n",
    "        \"\"\"Loads the ontology specified by source.\n",
    "        \n",
    "        Parameters:\n",
    "        - source: the source file for the ontology definition\n",
    "        - source_directory: the directory where the source files for the ontology definition are looked for.\n",
    "        If None (default) the default path provided by the `KnowledgeManager` is used.\"\"\"\n",
    "        self.__source= source\n",
    "        print(source)\n",
    "        try:\n",
    "            self.__onto = self.__ontology_backend.get_ontology(self.__source).load()\n",
    "        except Exception as err:\n",
    "            raise Exception(\"Unexpected exception received while loading ontology:\\n - source: {}\\n - onto_path: {}\".format(self.__source, self.__ontology_backend.onto_path))\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.__onto\n",
    "        \n",
    "    def get_ontology_backend(self):\n",
    "        \"\"\"Gets the ontology backend\"\"\"\n",
    "        assert self.__ontology_backend is not None, \"Trying to access the ontology backend without initialising it.\"\n",
    "        return self.__ontology_backend\n",
    "    \n",
    "    def sync_reasoner(self, **kargs):\n",
    "        \"\"\"Synchronise the reasoner.\n",
    "        \n",
    "        Parameters:\n",
    "        - **kargs:\n",
    "        |-infer_property_values\"\"\"\n",
    "        self.__ontology_backend.sync_reasoner(**kargs)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our approach, geological datasets will be progressively interpreted in terms of structural objects,<br>\n",
    "based on a formal definition of concepts own by a **GeologicalKnowledgeManager**.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager().reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager().load_knowledge_framework()\n",
    "GeologicalKnowledgeManager().get_knowledge_framework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeFramework(\"mogi\",\"mogi.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager().knowledge_framework_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mogi = GeologicalKnowledgeManager().get_knowledge_framework()\n",
    "mogi.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mogi().classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataset\n",
    "\n",
    "Data are actually described within the ontology, here thanks to the *Data* class.<br>\n",
    "Adding new data points calls for creating new *Data* individuals (i.e., instances in the ontology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_head = np.array(['name', 'x', 'y', 'z', 'dip_dir', 'dip', 'geology'])\n",
    "data_array = np.array([['D1', 15, 20, 35, 270, 45, 'Trias_Base'],\n",
    "                       ['D2', 30, 25, 50, 270, 45, 'Trias_Base'],\n",
    "                       ['D3', 60, 30, 40, 90, 45, 'Trias_Base'],\n",
    "                       ['D4', 75, 15, 25, 90, 45, 'Trias_Base'],\n",
    "                       ['D5', 110, 20, 40, 270, 63, 'Trias_Base'],\n",
    "                       ['D6', 120, 20, 60, 270, 64, 'Trias_Base'],\n",
    "                       ['D7', 155, 20, 60, 89, 39, 'Trias_Base'],\n",
    "                       ['D8', 190, 20, 30, 91, 40, 'Trias_Base'],\n",
    "                       ['D11', 25, 22, 45, np.nan, np.nan, np.nan],\n",
    "                       ['D22', 50, 22, 50, np.nan, np.nan, np.nan],\n",
    "                       ['D44', 100, 30, 20, np.nan, np.nan, np.nan],\n",
    "                       ['D77', 168, 30, 47, np.nan, np.nan, np.nan]]\n",
    ")\n",
    "dataset = pd.DataFrame(data = data_array, columns = data_head)\n",
    "dataset = dataset.astype({'name':str, 'x':float, 'y':float, 'z':float, 'dip_dir':float, 'dip':float, 'geology':str})\n",
    "dataset.set_index(\"name\", inplace = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing any data already stored in the ontology\n",
    "for data_i in mogi.search(type = mogi.Ponctual_Observation):\n",
    "    owl.destroy_entity(data_i)\n",
    "mogi.search(type = mogi.Ponctual_Observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the dataset in the ontology by creating individuals\n",
    "for name_i, values_i in dataset.iterrows():\n",
    "    mogi.Ponctual_Observation(name_i, **{key:[val] for key, val in values_i.items()})\n",
    "mogi.search(type = mogi.Ponctual_Observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading dataset from the ontology\n",
    "dataset = pd.DataFrame(columns=[\"name\",\"x\",\"y\",\"z\",\"dip_dir\",\"dip\",'geology'])\n",
    "dataset.set_index(\"name\",inplace=True)\n",
    "for di in mogi.search(type = mogi.Ponctual_Observation):\n",
    "    for prop in di.get_properties():\n",
    "        for value in prop[di]:\n",
    "            dataset.loc[di.name,prop.name] = value\n",
    "dataset = dataset.astype({'x':float, 'y':float, 'z':float, 'dip_dir':float, 'dip':float, 'geology':str})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Space(object):\n",
    "    \"\"\"A `Space` represents an abstract place where things exist and can be observed or rendered.\n",
    "    \n",
    "    It is typically dereived into:\n",
    "    - `PhysicalSpace` for spaces with physical coordinates (typically X, Y, Z)\n",
    "    - `TemporalSpace` for spaces with a time coordinate\"\"\"\n",
    "    \n",
    "class PhysicalSpace(Space):\n",
    "    \"\"\"A `PhysicalSpace` represents a physical place where things exist and can be observed or rendered.\"\"\"\n",
    "    \n",
    "class TemporalSpace(Space):\n",
    "    \"\"\"A `TemporalSpace` represents a time span where things exist and can be observed or rendered.\"\"\"\n",
    "\n",
    "class DataSet(object):\n",
    "    \"\"\"A `DataSet` gathers several kinds of data / observations / informations\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(center, dip, dir, length= 1, ax= None, color = \"black\", **kargs):\n",
    "    ax_plt = plt if ax is None else ax\n",
    "\n",
    "    center = np.array(center)\n",
    "    dip_rad = np.deg2rad(dip)\n",
    "    vec_x =  np.cos(dip_rad)\n",
    "    if dir == \"left\": vec_x *= -1\n",
    "    vec_z = -np.sin(dip_rad)\n",
    "    vect = 0.5 * length * np.array([vec_x,vec_z])\n",
    "    start = center - vect\n",
    "    end = center + vect\n",
    "    ax_plt.plot([start[0],end[0]],[start[1],end[1]], color = color, **kargs)\n",
    "    \n",
    "    return vect\n",
    "    \n",
    "def draw_dip_symbol(center, dip, dir, length= 1, polarity= None, ax= None, color = \"black\", polarity_ratio= 0.4, **kargs):\n",
    "    ax_plt = plt if ax is None else ax\n",
    "    \n",
    "    vect = draw_line(center= center, dip= dip, dir= dir, length= length, ax= ax_plt, color = color, **kargs)\n",
    "    \n",
    "    if polarity is not None:\n",
    "        vect_pol = polarity_ratio * np.array([-vect[1],vect[0]])\n",
    "        if (dir == \"left\" and polarity == \"up\") or (dir == \"right\" and polarity == \"down\") : vect_pol *= -1\n",
    "        ax_plt.arrow(*center,*vect_pol, width=length/100, color = color, **kargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_line([0,0],30, \"left\")\n",
    "draw_dip_symbol([0,1],60, \"right\", polarity= \"up\", color= \"red\" )\n",
    "plt.gca().set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dataset( dataset, ax= None, **kargs):\n",
    "    ax_plt = plt if ax is None else ax\n",
    "    \n",
    "    for data_i in dataset.itertuples():\n",
    "        if (data_i.dip != np.nan) and (data_i.dip_dir != np.nan):\n",
    "            dir = \"right\" if data_i.dip_dir < 180 else \"left\"\n",
    "            draw_dip_symbol( center= [data_i.x,data_i.z], dip= data_i.dip, dir= dir, **kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dataset(dataset, length=10, polarity=\"up\")\n",
    "plt.gca().set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(dataset.itertuples()).dip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We distinguish two kind of operations here:\n",
    "* representation\n",
    "* visualisation\n",
    "\n",
    "A representation is a formal description of how something appears in a given representation space, but it doesn't have to be visualised.<br>\n",
    "A visualisation takes care of the rendering of a representation with a given support (image, screen)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation should also be made a bit more abstract.<br>\n",
    "1. There is a variety of object that can be rendered in a representation space (typically, different kinds of a dataset components)\n",
    "2. Several kinds of representation spaces could be envisionned (e.g., spatial 1D,2D,3D, or temporal, or just an abstract text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RepresentationSpace(object):\n",
    "    \"\"\"A general framework for Representating geological objects\"\"\"\n",
    "    \n",
    "class TemporalRepresentationSpace(RepresentationSpace):\n",
    "    \"\"\"A `RepresentationSpace` representing temporal apsects of represented objects.\"\"\"\n",
    "    \n",
    "class PhysicalRepresentationSpace(RepresentationSpace):\n",
    "    \"\"\"A type of `RepresentationSpace` representing physical aspects of the represented objects.\"\"\"\n",
    "    \n",
    "    __default_coordinate_labels = [\"X\",\"Y\",\"Z\"]\n",
    "    \n",
    "    def __init__(self, dimension: int=None, coordinate_label: str|list= None ):\n",
    "        \"\"\"Initialisation of the representation space.\n",
    "        \n",
    "        Parameters:\n",
    "        - dimension (int): specify the number of dimensions of the representation space, typically 1D, 2D, or 3D (i.e., 1, 2, or 3),\n",
    "        NB: larger dimension spaces are not supported. At least either the `dimension` parameter or `coordinate_label` parameter should be given.\n",
    "        - coordinate_label(str|list(str)): gives the label(s) of the coordinates. If given, the number of dimensions is deduced from the size of the list\n",
    "        and `dimensions`is ignored, otherwise, the labels are taken from the `__default_coordinate_labels` based on the number of `dimension`s. \n",
    "        At least either the `dimension` parameter or `coordinate_label` parameter should be given.\n",
    "        \"\"\"\n",
    "        assert not (coordinate_label is None and dimension is None), \"At least one of the parameters shoudl be specified\"\n",
    "        if coordinate_label is None:\n",
    "            assert dimension in [1,2,3], \"The specified number of dimensions ({:d}) is not supported, should be 1, 2 or 3.\".format(dimension)\n",
    "            self.dimension= dimension\n",
    "            self.coordinate_labels= PhysicalRepresentationSpace.__default_coordinate_labels[:self.dimension]\n",
    "        elif isinstance(coordinate_label,str):\n",
    "            self.dimension= 1\n",
    "            self.coordinate_labels=  [coordinate_label]\n",
    "        elif isinstance(coordinate_label, list):\n",
    "            self.dimension= len(coordinate_label)\n",
    "            self.coordinate_labels= coordinate_label\n",
    "        else:\n",
    "            raise(\"Unsupported initialisation of representation space: dimension({}) and coordinate_label ({}).\\n At least one of the parameters shoudl be specified.\".format(dimension, coordinate_label))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PhysicalRepresentationSpace(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PhysicalRepresentationSpace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PhysicalRepresentationSpace(coordinate_label=[\"X\",\"Y\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeologicalDataset(object):\n",
    "    \"\"\"A GeologicalDataset gather information about geological data to be interpreted\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Workflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation process in itself is run in a **GeologicalInterpretationProcess** and follow a very simple and generic algorithm.<br>\n",
    "This algorithm implements a Deming wheel process of continual improvement:\n",
    "1. Plan:\n",
    "    1. Select a situation\n",
    "    2. Select an action\n",
    "2. Do: Implement the action (e.g., CreateInterpretationElement)\n",
    "    1. List features\n",
    "    2. Identify possible explanations\n",
    "    3. Rank/chose explanations\n",
    "    4. Instanciate individuals\n",
    "    5. Infer and set parameters\n",
    "3. Check: Evaluate consistency\n",
    "    1. Evaluate internal consistency\n",
    "    2. Evaluate relational likelihood\n",
    "    3. Evaluate feature explanation\n",
    "4. Act: Generate anomalies and report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeologicalInterpretationProcess(object):\n",
    "    \"\"\"GeologicalInterpretationProcess implements the core process of a geological intepretation.\n",
    "    \n",
    "    It connects all the required elements and resulting artefacts relatively to a given interpretation sequence:\n",
    "     - a GeologicalKnowledgeFramework\"\"\"\n",
    "     \n",
    "    def __init__(self, dataset: GeologicalDataset, knowledge_framework= None):\n",
    "         \"\"\"Creates a GeologicalInterpretationProcess\n",
    "         \n",
    "         ---------------------------\n",
    "         Parameters:\n",
    "         - dataset (GeologicalDataset): a dataset to be explained by this interpretor\n",
    "         - knowledge_framework: a GeologicalKnowledgeFramework that defines the concepts used for this interpretation.\n",
    "            If None is given, the the default knowledge framework is used (`GeologicalKnowledgeManager().get_knowledge_framework()`)\n",
    "         \"\"\"\n",
    "         self.knowledge_framework= GeologicalKnowledgeManager().get_knowledge_framework() if knowledge_framework is None else knowledge_framework\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
