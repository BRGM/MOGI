{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geological Interpretor Development"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for testing and developping some of the basic code in this package."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ontology manipulation\n",
    "\n",
    "The knowledge manipulated in this package is formalised in an ontology,<br>\n",
    "which is store in a *.owl* file.\n",
    "\n",
    "It is named **MOGI** for **M**inimal **O**ntology for **G**eological **I**nterpretation\n",
    "\n",
    "To manipulated this ontology, we use the package **owlready2** available from here: https://owlready2.readthedocs.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import owlready2 as owl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl.onto_path.append(\"../ontologies/\")\n",
    "mogi = owl.get_ontology(\"mogi.owl\").load()\n",
    "mogi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ontology provides access to its components, e.g.:\n",
    "* classes\n",
    "* properties\n",
    "* individuals\n",
    "* rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(mogi.classes()))\n",
    "print(list(mogi.properties()))\n",
    "print(list(mogi.individuals()))\n",
    "print(list(mogi.rules()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specific elements can be searched through simple queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mogi.search(iri = \"*Surface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = mogi.Geologic_Context('Data_properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.INDIRECT_get_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl.Thing.get_properties(owl.Thing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoner\n",
    "\n",
    "Ontologies are even more powerful thansk to their capabilities to use reasoning for infering types, properties, and relationships that were not explicitly stated.\n",
    "This is usefull for obtaining results implied by the already stated information.\n",
    "\n",
    "This is achieved by running a *reasoner* on the ontology as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl.sync_reasoner(infer_property_values=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geological Knowledge Manager"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GeologicalKnowledgeManager** may know different instances of **GeologicalKnowledgeFramework**,<br>\n",
    "for example to allow differenciating scenarios or for allowing customisation of knowledge and its formalisation.\n",
    "\n",
    "**GeologicalKnowledgeFramework** provides access to concept definitions for providing knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class GeologicalKnowledgeManager(object):\n",
    "    \"\"\"GeologicalKnowledgeManager is managing one or several GeologicalKnowledgeFramework.\n",
    "    \n",
    "    The GeologicalKnowledgeManager is typically a singleton, so there is always one and only one instance of it.\n",
    "    \n",
    "    The GeologicalKnowledgeManager may know different instances of GeologicalKnowledgeFramework,\n",
    "    for example to allow different interpretation scenarios or for allowing user-specific customisation\n",
    "    of knowledge and its formalisation.\n",
    "    \n",
    "    GeologicalKnowledgeFramework are typically ontologies and extensions defined in this package or elsewhere.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __new__(cls):\n",
    "        \"\"\"Method to access (and create if needed) the only allowed instance of this class.\n",
    "        \n",
    "        Returns:\n",
    "        - an instance of GeologicalKnowledgeManager\"\"\"\n",
    "        if not hasattr(cls, 'instance'):\n",
    "            cls.instance = super(GeologicalKnowledgeManager, cls).__new__(cls)\n",
    "            cls.initialised= False\n",
    "            print(\"DEBUG::creates new manager\")\n",
    "        return cls.instance\n",
    "        \n",
    "    def __init__(self, default= \"mogi\", source_directory= \"../ontologies/\", default_source_file= \"mogi.owl\", ontology_backend= \"owlready2\"):\n",
    "        \"\"\"Initializes the GeologicalKnowledgeManager with some default values from configuration.\n",
    "        \n",
    "        Parameters:\n",
    "        - default: specifies the name of the default knowledge framework\n",
    "        - source_directory: specifies the default folder containing of the knowledge framework definitions\n",
    "        - default_source_file: file contained in the source_directory defining the knowledge framework (e.g., .owl file)\n",
    "        - ontology_backend: specifies the default ontology backend to be used\n",
    "        \"\"\"\n",
    "        print(\"DEBUG::__init__\")\n",
    "        if not self.initialised:\n",
    "            self._initialise(default= default, source_directory= source_directory, default_source_file= default_source_file, ontology_backend= ontology_backend)\n",
    "            \n",
    "    def _initialise(self, default= \"mogi\", source_directory= \"../ontologies/\", default_source_file= \"mogi.owl\", ontology_backend= \"owlready2\"):\n",
    "        \"\"\"Initializes the GeologicalKnowledgeManager with some default values from configuration.\n",
    "        \n",
    "        Parameters:\n",
    "        - default: specifies the name of the default knowledge framework\n",
    "        - source_directory: specifies the default folder containing of the knowledge framework definitions\n",
    "        - default_source_file: file contained in the source_directory defining the knowledge framework (e.g., .owl file)\n",
    "        - ontology_backend: specifies the default ontology backend to be used\n",
    "        \"\"\"\n",
    "        print(\"DEBUG::initialize manager\")\n",
    "        self.default= default\n",
    "        self.source_directory= source_directory\n",
    "        self.default_source_file= default_source_file\n",
    "        self.default_ontology_backend= ontology_backend\n",
    "        \n",
    "        self.__ontology_backend = None\n",
    "        self.initialise_ontology_backend(ontology_backend)\n",
    "        self.knowledge_framework_dict = {}\n",
    "        \n",
    "        self.initialised= True\n",
    "        \n",
    "    def reset(self, default= \"mogi\", source_directory= \"../ontologies/\", default_source_file= \"mogi.owl\", ontology_backend= \"owlready2\"):\n",
    "        \"\"\"Reinitializes the GeologicalKnowledgeManager with some default values from configuration.\n",
    "        \n",
    "        Parameters:\n",
    "        - default: specifies the name of the default knowledge framework\n",
    "        - source_directory: specifies the default folder containing of the knowledge framework definitions\n",
    "        - default_source_file: file contained in the source_directory defining the knowledge framework (e.g., .owl file)\n",
    "        - ontology_backend: specifies the default ontology backend to be used\n",
    "        \"\"\"\n",
    "        print(\"DEBUG::reset manager\")\n",
    "        self._initialise(default= default, source_directory= source_directory, default_source_file= default_source_file, ontology_backend= ontology_backend)\n",
    "    \n",
    "    def initialise_ontology_backend(self, backend:str= None):\n",
    "        \"\"\"Initializes the ontology package used as a backend to access ontologies.\n",
    "        \n",
    "        This will:\n",
    "        - try to import the backend as onto\n",
    "        - set the default path for ontologies\"\"\"\n",
    "        backend= self.default_ontology_backend if backend is None else backend\n",
    "        if backend == \"owlready2\":\n",
    "            try:\n",
    "                import owlready2 as owl2 \n",
    "                self.__ontology_backend = owl2\n",
    "                self.__ontology_backend.onto_path.append(self.source_directory)\n",
    "            except ImportError:\n",
    "                raise ImportError(\"Your are trying to use Owlready2 as a backend for ontology management, but it doesn't appear to be installed.\"\\\n",
    "                \"This is either because OwlReady2 is given as default option or because you asked for it.\"\\\n",
    "                \"Please install the OwlReady2 package from https://owlready2.readthedocs.io\"\\\n",
    "                \"or give another backend through GeologicalKnowledgeManager().initialise_ontology_backend()\")\n",
    "                \n",
    "            # also test if java is correctly installed & accessible, as it is used by owlready2 for reasoning\n",
    "            try:\n",
    "                os.system(\"java -version\")\n",
    "            except:\n",
    "                raise ImportError(\"Java doesn't appear to be installed properly as the command `java -version` returned an error.\"\\\n",
    "                    \"This error occured while loading owlready2 package as an ontology backend, because java is used for the reasoning engine.\")\n",
    "        else:\n",
    "            raise Exception(\"The specified backed for ontology is not supported: \"+backend)\n",
    "         \n",
    "    def load_knowledge_framework(self, name=None, source= None):\n",
    "        \"\"\"Gets and initilises the ontology from the specified source.\n",
    "        \n",
    "        Parameters:\n",
    "        - nickname: the name to be given to the knowledge framework. If None (default) the file name will be used\n",
    "        - source: filename to the ontology source. If None(default) the default ontology is used.\"\"\"\n",
    "        source = source if source is not None else self.default_source_file\n",
    "        name = name if name is not None else os.path.basename(source).split(os.path.extsep)[0]\n",
    "        self.knowledge_framework_dict[name] = GeologicalKnowledgeFramework(name, source)\n",
    "        \n",
    "    def get_ontology_backend(self):\n",
    "        \"\"\"Gets the ontology backend\"\"\"\n",
    "        assert self.__ontology_backend is not None, \"Trying to access the ontology backend without initialising it.\"\n",
    "        return self.__ontology_backend\n",
    "    \n",
    "    def get_knowledge_framework(self,name= \"default\"):\n",
    "        \"\"\"Accessor to knowledge frameworks.\"\"\"\n",
    "        name = self.default if name == \"default\" else name\n",
    "        assert len(self.knowledge_framework_dict) > 0, \"No ontology has been loaded yet. Please use GeologicalKnowledgeManager().load_knowledge_framework() first\"\n",
    "        assert name in self.knowledge_framework_dict.keys(), \"The specified ontology hasn't been loaded: \"+name+\\\n",
    "            \"\\navailable ontology names are: \"+\"\\n\".join(self.knowledge_framework_dict.keys())\n",
    "        return self.knowledge_framework_dict[name]\n",
    "    \n",
    "class GeologicalKnowledgeFramework(object):\n",
    "    \"\"\"A GeologicalKnowledgeFramework holds the definition of concepts and relationships describing knowledge.\n",
    "    \n",
    "    This is typically an overlay around a formal ontology definition, which also brings additional capabilities,\n",
    "    such as algorithms and factories to achieve specific tasks and create objects.\"\"\"\n",
    "    \n",
    "    def __init__(self, name, source):\n",
    "        \"\"\"Initialise a KnowledgeFramework form a given ontology file (source).\n",
    "        \n",
    "        Parameters:\n",
    "        - name: should be the name under which this KnowledgeFramework is known in the manager\n",
    "        - source: the source file for the ontology definition\"\"\"\n",
    "        self.name= name\n",
    "        self.onto = GeologicalKnowledgeManager().get_ontology_backend().get_ontology(source).load()\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.onto\n",
    "        \n",
    "    def sync_reasoner(self, **kargs):\n",
    "        \"\"\"Synchronise the reasoner.\n",
    "        \n",
    "        Parameters:\n",
    "        - **kargs:\n",
    "        |-infer_property_values\"\"\"\n",
    "        GeologicalKnowledgeManager().get_ontology_backend().sync_reasoner(infer_property_values=True)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our approach, geological datasets will be progressively interpreted in terms of structural objects,<br>\n",
    "based on a formal definition of concepts own by a **GeologicalKnowledgeManager**.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager().reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager().initialise_ontology_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager().load_knowledge_framework()\n",
    "GeologicalKnowledgeManager().get_knowledge_framework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GeologicalKnowledgeManager().knowledge_framework_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mogi = GeologicalKnowledgeManager().get_knowledge_framework()\n",
    "mogi.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mogi.onto.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mogi().classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataset\n",
    "\n",
    "Data are actually described within the ontology, here thanks to the *Data* class.<br>\n",
    "Adding new data points calls for creating new *Data* individuals (i.e., instances in the ontology)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_head = np.array(['name', 'x', 'y', 'z', 'dip_dir', 'dip', 'geology'])\n",
    "data_array = np.array([['D1', 15, 20, 35, 270, 45, 'Trias_Base'],\n",
    "                       ['D2', 30, 25, 50, 270, 45, 'Trias_Base'],\n",
    "                       ['D3', 60, 30, 40, 90, 45, 'Trias_Base'],\n",
    "                       ['D4', 75, 15, 25, 90, 45, 'Trias_Base'],\n",
    "                       ['D5', 110, 20, 40, 270, 63, 'Trias_Base'],\n",
    "                       ['D6', 120, 20, 60, 270, 64, 'Trias_Base'],\n",
    "                       ['D7', 155, 20, 60, 89, 39, 'Trias_Base'],\n",
    "                       ['D8', 190, 20, 30, 91, 40, 'Trias_Base'],\n",
    "                       ['D11', 25, 22, 45, np.nan, np.nan, np.nan],\n",
    "                       ['D22', 50, 22, 50, np.nan, np.nan, np.nan],\n",
    "                       ['D44', 100, 30, 20, np.nan, np.nan, np.nan],\n",
    "                       ['D77', 168, 30, 47, np.nan, np.nan, np.nan]]\n",
    ")\n",
    "dataset = pd.DataFrame(data = data_array, columns = data_head)\n",
    "dataset = dataset.astype({'name':str, 'x':float, 'y':float, 'z':float, 'dip_dir':float, 'dip':float, 'geology':str})\n",
    "dataset.set_index(\"name\", inplace = True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearing any data already stored in the ontology\n",
    "for data_i in mogi.search(type = mogi.Ponctual_Observation):\n",
    "    owl.destroy_entity(data_i)\n",
    "mogi.search(type = mogi.Ponctual_Observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the dataset in the ontology by creating individuals\n",
    "for name_i, values_i in dataset.iterrows():\n",
    "    mogi.Ponctual_Observation(name_i, **{key:[val] for key, val in values_i.items()})\n",
    "mogi.search(type = mogi.Ponctual_Observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading dataset from the ontology\n",
    "dataset = pd.DataFrame(columns=[\"name\",\"x\",\"y\",\"z\",\"dip_dir\",\"dip\",'geology'])\n",
    "dataset.set_index(\"name\",inplace=True)\n",
    "for di in mogi.search(type = mogi.Ponctual_Observation):\n",
    "    for prop in di.get_properties():\n",
    "        for value in prop[di]:\n",
    "            dataset.loc[di.name,prop.name] = value\n",
    "dataset = dataset.astype({'x':float, 'y':float, 'z':float, 'dip_dir':float, 'dip':float, 'geology':str})\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Space(object):\n",
    "    \"\"\"A `Space` represents an abstract place where things exist and can be observed or rendered.\n",
    "    \n",
    "    It is typically dereived into:\n",
    "    - `PhysicalSpace` for spaces with physical coordinates (typically X, Y, Z)\n",
    "    - `TemporalSpace` for spaces with a time coordinate\"\"\"\n",
    "    \n",
    "class PhysicalSpace(Space):\n",
    "    \"\"\"A `PhysicalSpace` represents a physical place where things exist and can be observed or rendered.\"\"\"\n",
    "    \n",
    "class TemporalSpace(Space):\n",
    "    \"\"\"A `TemporalSpace` represents a time span where things exist and can be observed or rendered.\"\"\"\n",
    "\n",
    "class DataSet(object):\n",
    "    \"\"\"A `DataSet` gathers several kinds of data / observations / informations\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_line(center, dip, dir, length= 1, ax= None, color = \"black\", **kargs):\n",
    "    ax_plt = plt if ax is None else ax\n",
    "\n",
    "    center = np.array(center)\n",
    "    dip_rad = np.deg2rad(dip)\n",
    "    vec_x =  np.cos(dip_rad)\n",
    "    if dir == \"left\": vec_x *= -1\n",
    "    vec_z = -np.sin(dip_rad)\n",
    "    vect = 0.5 * length * np.array([vec_x,vec_z])\n",
    "    start = center - vect\n",
    "    end = center + vect\n",
    "    ax_plt.plot([start[0],end[0]],[start[1],end[1]], color = color, **kargs)\n",
    "    \n",
    "    return vect\n",
    "    \n",
    "def draw_dip_symbol(center, dip, dir, length= 1, polarity= None, ax= None, color = \"black\", polarity_ratio= 0.4, **kargs):\n",
    "    ax_plt = plt if ax is None else ax\n",
    "    \n",
    "    vect = draw_line(center= center, dip= dip, dir= dir, length= length, ax= ax_plt, color = color, **kargs)\n",
    "    \n",
    "    if polarity is not None:\n",
    "        vect_pol = polarity_ratio * np.array([-vect[1],vect[0]])\n",
    "        if (dir == \"left\" and polarity == \"up\") or (dir == \"right\" and polarity == \"down\") : vect_pol *= -1\n",
    "        ax_plt.arrow(*center,*vect_pol, width=length/100, color = color, **kargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_line([0,0],30, \"left\")\n",
    "draw_dip_symbol([0,1],60, \"right\", polarity= \"up\", color= \"red\" )\n",
    "plt.gca().set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dataset( dataset, ax= None, **kargs):\n",
    "    ax_plt = plt if ax is None else ax\n",
    "    \n",
    "    for data_i in dataset.itertuples():\n",
    "        if (data_i.dip != np.nan) and (data_i.dip_dir != np.nan):\n",
    "            dir = \"right\" if data_i.dip_dir < 180 else \"left\"\n",
    "            draw_dip_symbol( center= [data_i.x,data_i.z], dip= data_i.dip, dir= dir, **kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dataset(dataset, length=10, polarity=\"up\")\n",
    "plt.gca().set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(dataset.itertuples()).dip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation should also be made a bit more abstract.<br>\n",
    "1. There is a variety of object that can be rendered in a visualisation space (typically, different kinds of a dataset components)\n",
    "2. Several kinds of visualisation spaces could be envisionned (e.g., spatial 1D,2D,3D, or temporal, or just an abstract text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualisationSpace(object):\n",
    "    \"\"\"A general framework for visualising geological objects\"\"\"\n",
    "    \n",
    "class PhysicalVisualisationSpace(VisualisationSpace):\n",
    "    \"\"\"A type of `VisualisationSpace` rendering physical aspects of the visualised objects.\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Workflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation process in itself is run in a **GeologicalInterpretationProcess** and follow a very simple and generic algorithm.<br>\n",
    "This algorithm implements a Deming wheel process of continual improvement:\n",
    "1. Plan:\n",
    "    1. Select a situation\n",
    "    2. Select an action\n",
    "2. Do: Implement the action (e.g., CreateInterpretationElement)\n",
    "    1. List features\n",
    "    2. Identify possible explanations\n",
    "    3. Rank/chose explanations\n",
    "    4. Instanciate individuals\n",
    "    5. Infer and set parameters\n",
    "3. Check: Evaluate consistency\n",
    "    1. Evaluate internal consistency\n",
    "    2. Evaluate relational likelihood\n",
    "    3. Evaluate feature explanation\n",
    "4. Act: Generate anomalies and report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeologicalInterpretationProcess(object):\n",
    "    \"\"\"GeologicalInterpretationProcess implements the core process of a geological intepretation.\n",
    "    \n",
    "    It connects all the required elements and resulting artefacts relatively to a given interpretation sequence:\n",
    "     - a GeologicalKnowledgeFramework\"\"\"\n",
    "     \n",
    "     def __init__(self, dataset: GeologicalDataset, knowledge_framework= None):\n",
    "         \"\"\"Creates a GeologicalInterpretationProcess\n",
    "         \n",
    "         ---------------------------\n",
    "         Parameters:\n",
    "         - dataset (GeologicalDataset): a dataset to be explained by this interpretor\n",
    "         - knowledge_framework: a GeologicalKnowledgeFramework that defines the concepts used for this interpretation.\n",
    "            If None is given, the the default knowledge framework is used (`GeologicalKnowledgeManager().get_knowledge_framework()`)\n",
    "         \"\"\"\n",
    "         self.knowledge_framework= GeologicalKnowledgeManager().get_knowledge_framework() if knowledge_framework is None else knowledge_framework\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
